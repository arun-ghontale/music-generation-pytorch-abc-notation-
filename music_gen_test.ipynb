{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    flat_list = []\n",
    "    for sublist in l:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    \n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "notation_to_idx = load_obj('notation_to_idx')\n",
    "idx_to_notation = load_obj('idx_to_notation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "##creating the RNN class\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        ##input size same as the number of unique characters\n",
    "        self.input_size = input_size\n",
    "        ##hidden size decides the number of LSTM units. The output size is same as the hidden size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        ##number of layers for the GRU which by default is 1\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        ##initialize the embedding layer to convert the words to their embedding vectors\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        ###gru with the same input and hidden size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        ###decoder is the a linear layer whose output is of dimension output_size(generally the number of characters \n",
    "        ##because that is what we are predicting)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        ##the forward propogation\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        ##hidden vector initialized with all zeros\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([66, 43,  7, 82, 15, 37, 24, 43,  8, 28, 63, 63, 90, 88])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def music_tensor(notations_list):\n",
    "    tensor = torch.zeros(len(notations_list)).long()\n",
    "    for c in range(len(notations_list)):\n",
    "        tensor[c] = notation_to_idx[notations_list[c]]\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(music_tensor(list(\"X: 47\\nT:Navvie\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###given a prime notation, that is character of starting strings predict the next characters in sequence\n",
    "###the multinomial decides whether to sample from the last layer(in which case we can get 2nd or 3rd \n",
    "### best character as output as well) or use argmax of the last layer(basically consider the most probable output only)\n",
    "def evaluate(prime_notation='2.7', predict_len=100, temperature=0.8, use_multinomial = True):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = music_tensor(prime_notation)\n",
    "    predicted = prime_notation\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_notation) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        if not use_multinomial:\n",
    "            output, hidden = decoder(inp, hidden)\n",
    "            _, index_top = torch.topk(output.view(-1),1)\n",
    "            predicted_notation = idx_to_notation[index_top.numpy()[0]]\n",
    "            predicted += predicted_notation\n",
    "            inp = music_tensor([predicted_notation])\n",
    "\n",
    "        else:\n",
    "            output, hidden = decoder(inp, hidden)            \n",
    "            # Sample from the network as a multinomial distribution\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0]\n",
    "            # Add predicted character to string and use as next input\n",
    "            predicted_notation = idx_to_notation[top_i.view(-1).numpy()[0]]\n",
    "            predicted += predicted_notation\n",
    "            inp = music_tensor([predicted_notation])\n",
    "\n",
    "            \n",
    "#     for p in range(predict_len):\n",
    "#         output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "#         # Sample from the network as a multinomial distribution\n",
    "#         output_dist = output.data.view(-1).div(temperature).exp()\n",
    "#         top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "#         # Add predicted character to string and use as next input\n",
    "#         predicted_char = all_characters[top_i]\n",
    "#         predicted += predicted_char\n",
    "#         inp = char_tensor(predicted_char)\n",
    "\n",
    "    return \"\".join(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (encoder): Embedding(93, 143)\n",
       "  (gru): GRU(143, 143)\n",
       "  (decoder): Linear(in_features=143, out_features=93, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##load the pre-trained model\n",
    "n_notations = len(notation_to_idx)\n",
    "hidden_size = n_notations+50\n",
    "n_layers = 1\n",
    "\n",
    "decoder = RNN(n_notations, hidden_size, n_notations, n_layers)\n",
    "decoder.load_state_dict(torch.load(r\"C:\\Users\\arun\\Desktop\\Projects\\practical-pytorch\\char-rnn-generation\\music_gen.pth\"))\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 39\n",
      "T:Monton Domana\n",
      "% Nottingham Music Database\n",
      "S:Mick Peat\n",
      "M:4/4\n",
      "L:1/8\n",
      "R:Hornpipe\n",
      "K:D\n",
      "P:A\n",
      "|:A|\"D\"f3/2f/2a3/2f/2g/2a/2|\"D\"dcdf \"A7\"eA(3ABc|\n",
      "\"D\"dAAA ABAA|\"G\"GABc dcdd|\"Em\"gagf \"A7\"afed|\n",
      "\"D\"ABAF DEFA|\"G\"BABA \"D\"F2d2|\"D\"A2A2 A2D2|\"A7\"EAAd cBA2|\n",
      "\"D\"DFA2a aAdc|\"G\"BAGF \"A7\"EGAB|\"D\"A2FA fdAd|\n",
      "\"G\"edAB \"D7\"AFAF|\"G\"BdBd \"D\"fdfe|\"G\"dede \"A7\"EAef|\"D\"f2ed AFAd|\"G\"B2dB cBA|\"G\"d4ddd d2dB|1\"A7/c+\"cBAA ABcA|\"D\"d2A2a agfd|\"Em\"gfeB dcBc|\"Em\"B2d2e2|\"A7\"efga agec|\"D\"dfdd \"E7\"edcB|\"A7\"ABAF \"D\"FAdcd|\n",
      "\"G/b\"eded \"E7\"edfg|\"A\"efef edcd|\n",
      "\"D\"f3fe dAFA|\"G\"d3 -d2d|\"D\"Adf2 fedc|\n",
      "\"G\"d2gd \"E7\"BBd|\"G\"BAGF \"D\"A2f2|\"Em\"g2A BcBc|\"G\"B2BA d2dd|\"G\"d2d \"A7\"ABAG|\n",
      "\"D\"FFA \"D\"ddddf|\"A7\"gefe edcd|\n",
      "\"D\"fdfe \"G\"defe|\"D\"d2f2 A3/2f3/4a/4g/4f/4e/4d/4d/4c/4A/4A/4A/4A/4B/4A/4F/4F/4A/4B/4A/4(3aast\n",
      "M:4/4\n",
      "L:1/8\n",
      "R:Hornpipe\n",
      "K:D\n",
      "P:A\n",
      "(3D/2F/2|\"G\"GAGF dGBd|\"Em\"g2g2 fga|\"D\"\"D\"fdcd \"A7\"EA(3ABc|\"D\"d3 d3:|\n",
      "EOS\n",
      "\n",
      "X: 204\n",
      "T:Thce Dow Dewes Lours of Peen Bess\n",
      "% Nottingham Music Database\n",
      "S:AAAd FFTreassh, via EF\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "\"G\"GG \"C\"DE|\"G\"DG GF|\"Em\"GE \"D7\"e/2d/2c/2B/2|\"D\"A/2B/2A/2F/2 \"D7\"A/2A/2B/2A/2|\"G\"GG \"C\"EG|\"Em\"EE EG|\"D\"A2 A|\"D7\"A3/2^A/2 A/2B/2c/2d/2|\"G\"g/2f/2d/2B/2 \"G\"GB|\n",
      "\"G\"DG DB|\"D7\"AA AF|\"G\"GA d/2B/2G/2B/2|\"G\"B/2d/2B/2c/2 BA/2d/2|\"C\"ee gf/2e/2|\\\n",
      "\"G\"d/2c/4B/4 \"G\"B/4d/4B/4|\"Em\"G/2E/2F/2E/2 GE/2G/2|\"A7\"Dd ge|\"D\"d/2e/2f/2g/2 f/2d/2f/2g/2|\"G\"gd \"D7\"AB|\"G\"GD dc|\"G\"dd \"D7\"A/2B/c\"GB|\n",
      "\"G\"d/2B/2A/2B/2 \"D7\"A/2B/2A/2F/2|\"G\"GA GA|\"G\"B/2A/2G/2F/2 \"D7\"GF|\"G\"G/2F/2D/2E/2 GF|\"G\"G/4A/4B/4c/4B/4 \"D7\"A/4A/4A/4A/4|\n",
      "\"G\"B/4A/4G/4 \"D7\"A/4B/4A/4|\"G\"G/4A/4B/4 \"D\"A/4c\n"
     ]
    }
   ],
   "source": [
    "#generate random lyrics and paste the generated notation here: https://abcjs.net/abcjs-editor.html\n",
    "##Note: EOS token separates one song notation from another\n",
    "prime = \"\"\"X: 39\n",
    "T:\"\"\"\n",
    "print(evaluate(prime, 1500, temperature=0.7, use_multinomial=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
