{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    flat_list = []\n",
    "    for sublist in l:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    \n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "notation_to_idx = load_obj('notation_to_idx')\n",
    "idx_to_notation = load_obj('idx_to_notation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "##creating the RNN class\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        ##input size same as the number of unique characters\n",
    "        self.input_size = input_size\n",
    "        ##hidden size decides the number of LSTM units. The output size is same as the hidden size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        ##number of layers for the GRU which by default is 1\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        ##initialize the embedding layer to convert the words to their embedding vectors\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        ###gru with the same input and hidden size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        ###decoder is the a linear layer whose output is of dimension output_size(generally the number of characters \n",
    "        ##because that is what we are predicting)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        ##the forward propogation\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        ##hidden vector initialized with all zeros\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([59])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def music_tensor(notations_list):\n",
    "    tensor = torch.zeros(len(notations_list)).long()\n",
    "    for c in range(len(notations_list)):\n",
    "        tensor[c] = notation_to_idx[notations_list[c]]\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(music_tensor(list(\"[\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###given a prime notation, that is character of starting strings predict the next characters in sequence\n",
    "###the multinomial decides whether to sample from the last layer(in which case we can get 2nd or 3rd \n",
    "### best character as output as well) or use argmax of the last layer(basically consider the most probable output only)\n",
    "def evaluate(prime_notation='[', predict_len=100, temperature=0.8, use_multinomial = True):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = music_tensor(prime_notation)\n",
    "    predicted = prime_notation\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_notation) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        if not use_multinomial:\n",
    "            output, hidden = decoder(inp, hidden)\n",
    "            _, index_top = torch.topk(output.view(-1),1)\n",
    "            predicted_notation = idx_to_notation[index_top.numpy()[0]]\n",
    "            predicted += predicted_notation\n",
    "            inp = music_tensor([predicted_notation])\n",
    "\n",
    "        else:\n",
    "            output, hidden = decoder(inp, hidden)            \n",
    "            # Sample from the network as a multinomial distribution\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0]\n",
    "            # Add predicted character to string and use as next input\n",
    "            predicted_notation = idx_to_notation[top_i.view(-1).numpy()[0]]\n",
    "            predicted += predicted_notation\n",
    "            inp = music_tensor([predicted_notation])\n",
    "\n",
    "            \n",
    "#     for p in range(predict_len):\n",
    "#         output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "#         # Sample from the network as a multinomial distribution\n",
    "#         output_dist = output.data.view(-1).div(temperature).exp()\n",
    "#         top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "#         # Add predicted character to string and use as next input\n",
    "#         predicted_char = all_characters[top_i]\n",
    "#         predicted += predicted_char\n",
    "#         inp = char_tensor(predicted_char)\n",
    "\n",
    "    return \"\".join(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RNN:\n\tsize mismatch for encoder.weight: copying a param with shape torch.Size([78, 48]) from checkpoint, the shape in current model is torch.Size([78, 128]).\n\tsize mismatch for gru.weight_ih_l0: copying a param with shape torch.Size([144, 48]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n\tsize mismatch for gru.weight_hh_l0: copying a param with shape torch.Size([144, 48]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n\tsize mismatch for gru.bias_ih_l0: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for gru.bias_hh_l0: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.weight: copying a param with shape torch.Size([78, 48]) from checkpoint, the shape in current model is torch.Size([78, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-79bdb3c1d7a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_notations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_notations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\chinn\\Desktop\\AppliedAI\\DEEP LEARNING\\Music Generation\\music-generation-pytorch-abc-notation--master\\music_gen.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 769\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RNN:\n\tsize mismatch for encoder.weight: copying a param with shape torch.Size([78, 48]) from checkpoint, the shape in current model is torch.Size([78, 128]).\n\tsize mismatch for gru.weight_ih_l0: copying a param with shape torch.Size([144, 48]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n\tsize mismatch for gru.weight_hh_l0: copying a param with shape torch.Size([144, 48]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n\tsize mismatch for gru.bias_ih_l0: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for gru.bias_hh_l0: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.weight: copying a param with shape torch.Size([78, 48]) from checkpoint, the shape in current model is torch.Size([78, 128])."
     ]
    }
   ],
   "source": [
    "##load the pre-trained model\n",
    "n_notations = len(notation_to_idx)\n",
    "hidden_size = n_notations+50\n",
    "n_layers = 1\n",
    "\n",
    "decoder = RNN(n_notations, hidden_size, n_notations, n_layers)\n",
    "decoder.load_state_dict(torch.load(r\"C:\\Users\\chinn\\Desktop\\AppliedAI\\DEEP LEARNING\\Music Generation\\music-generation-pytorch-abc-notation--master\\music_gen.pth\"))\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 39\n",
      "T:Monton Domana\n",
      "% Nottingham Music Database\n",
      "S:Mick Peat\n",
      "M:4/4\n",
      "L:1/8\n",
      "R:Hornpipe\n",
      "K:D\n",
      "P:A\n",
      "|:A|\"D\"f3/2f/2a3/2f/2g/2a/2|\"D\"dcdf \"A7\"eA(3ABc|\n",
      "\"D\"dAAA ABAA|\"G\"GABc dcdd|\"Em\"gagf \"A7\"afed|\n",
      "\"D\"ABAF DEFA|\"G\"BABA \"D\"F2d2|\"D\"A2A2 A2D2|\"A7\"EAAd cBA2|\n",
      "\"D\"DFA2a aAdc|\"G\"BAGF \"A7\"EGAB|\"D\"A2FA fdAd|\n",
      "\"G\"edAB \"D7\"AFAF|\"G\"BdBd \"D\"fdfe|\"G\"dede \"A7\"EAef|\"D\"f2ed AFAd|\"G\"B2dB cBA|\"G\"d4ddd d2dB|1\"A7/c+\"cBAA ABcA|\"D\"d2A2a agfd|\"Em\"gfeB dcBc|\"Em\"B2d2e2|\"A7\"efga agec|\"D\"dfdd \"E7\"edcB|\"A7\"ABAF \"D\"FAdcd|\n",
      "\"G/b\"eded \"E7\"edfg|\"A\"efef edcd|\n",
      "\"D\"f3fe dAFA|\"G\"d3 -d2d|\"D\"Adf2 fedc|\n",
      "\"G\"d2gd \"E7\"BBd|\"G\"BAGF \"D\"A2f2|\"Em\"g2A BcBc|\"G\"B2BA d2dd|\"G\"d2d \"A7\"ABAG|\n",
      "\"D\"FFA \"D\"ddddf|\"A7\"gefe edcd|\n",
      "\"D\"fdfe \"G\"defe|\"D\"d2f2 A3/2f3/4a/4g/4f/4e/4d/4d/4c/4A/4A/4A/4A/4B/4A/4F/4F/4A/4B/4A/4(3aast\n",
      "M:4/4\n",
      "L:1/8\n",
      "R:Hornpipe\n",
      "K:D\n",
      "P:A\n",
      "(3D/2F/2|\"G\"GAGF dGBd|\"Em\"g2g2 fga|\"D\"\"D\"fdcd \"A7\"EA(3ABc|\"D\"d3 d3:|\n",
      "EOS\n",
      "\n",
      "X: 204\n",
      "T:Thce Dow Dewes Lours of Peen Bess\n",
      "% Nottingham Music Database\n",
      "S:AAAd FFTreassh, via EF\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "\"G\"GG \"C\"DE|\"G\"DG GF|\"Em\"GE \"D7\"e/2d/2c/2B/2|\"D\"A/2B/2A/2F/2 \"D7\"A/2A/2B/2A/2|\"G\"GG \"C\"EG|\"Em\"EE EG|\"D\"A2 A|\"D7\"A3/2^A/2 A/2B/2c/2d/2|\"G\"g/2f/2d/2B/2 \"G\"GB|\n",
      "\"G\"DG DB|\"D7\"AA AF|\"G\"GA d/2B/2G/2B/2|\"G\"B/2d/2B/2c/2 BA/2d/2|\"C\"ee gf/2e/2|\\\n",
      "\"G\"d/2c/4B/4 \"G\"B/4d/4B/4|\"Em\"G/2E/2F/2E/2 GE/2G/2|\"A7\"Dd ge|\"D\"d/2e/2f/2g/2 f/2d/2f/2g/2|\"G\"gd \"D7\"AB|\"G\"GD dc|\"G\"dd \"D7\"A/2B/c\"GB|\n",
      "\"G\"d/2B/2A/2B/2 \"D7\"A/2B/2A/2F/2|\"G\"GA GA|\"G\"B/2A/2G/2F/2 \"D7\"GF|\"G\"G/2F/2D/2E/2 GF|\"G\"G/4A/4B/4c/4B/4 \"D7\"A/4A/4A/4A/4|\n",
      "\"G\"B/4A/4G/4 \"D7\"A/4B/4A/4|\"G\"G/4A/4B/4 \"D\"A/4c\n"
     ]
    }
   ],
   "source": [
    "#generate random lyrics and paste the generated notation here: https://abcjs.net/abcjs-editor.html\n",
    "##Note: EOS token separates one song notation from another\n",
    "prime = \"\"\"X: 39\n",
    "T:\"\"\"\n",
    "print(evaluate(prime, 1500, temperature=0.7, use_multinomial=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
